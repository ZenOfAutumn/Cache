# 事务#


##数据结构

###简单动态字符串（Simple Dynamic String）

####源码
```c
struct sdshdr {
    // buf 中已占用空间的长度
    int len;

    // buf 中剩余可用空间的长度
    int free;

    // 数据空间
    char buf[];
};
```
####SDS与C字符串的区别 
1. 如果求C语言中的字符串的长度，直到遇到’\0’结束，时间复杂度为O(n)；而SDS中的字符串长度，有一个成员记录着字符串的长度，所以时间复杂度为O(1)，这确保了获取字符串长度的工作不会成为Redis的性能瓶颈。
2. 杜绝缓冲区溢出 
  C语言中的strcat();利用这个函数进行字符串的拷贝时，这个函数内部是默认已经分配够空间的，如果我们在调用之前忘记给目的字符串分配够空间，那么就会发生字符串的溢出；而SDS中提供的接口sdscat()，如果空间不够，可以自动扩容。 
3. 减少修改字符串时带来的内存重分配次数 
- 空间预分配用于优化SDS的字符串增长的操作；如果SDS的长度小于1MB，那么程序分配和len属性同样大小的未使用空间；如果大于1MB，程序会分配1MB的未使用空间。
- 惰性空间释放用于优化SDS的字符串缩短的操作；当程序需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性记录，将回收的空间记录起来。 
4. 二进制安全 
  C字符串中的字符必须符合某种编码，并且除了字符串的末尾之外，字符串里面不能包含空字符，这个限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据；
  SDS读取数据的时候，是根据len属性进行读取的，所以不存在遇到空字符串就结束的说法，SDS的API都是二进制安全的，所有SDS的API都会以处理二进制的方式处理存在SDS存放在buf数组里的数据，程序不会对其中的数据做任何限制、过滤，数据写入是什么样子，读取出来就是什么样子。把SDS中的buf称为字节数组是因为，它不是用buf来保存字符，而是用来保存一系列二进制数据。Redis不仅可以保存文本数据，还可以保存任意格式的二进制数据。
5. 兼容部分C字符串函数
  虽然SDS的API是二进制安全的，但它们一样遵循C字符串以空字符结尾的惯例，这是为了让那些保存文本数据的SDS可以重用一部分<string.h>库定义的函数。


###链表（Double Linked List）

####源码
```c
/*
 * 双端链表节点
 */
typedef struct listNode {

    // 前置节点
    struct listNode *prev;

    // 后置节点
    struct listNode *next;

    // 节点的值
    void *value;

} listNode;
```

```c
/*
 * 双端链表结构
 */
typedef struct list {

    // 表头节点
    listNode *head;

    // 表尾节点
    listNode *tail;

    // 节点值复制函数
    void *(*dup)(void *ptr);

    // 节点值释放函数
    void (*free)(void *ptr);

    // 节点值对比函数
    int (*match)(void *ptr, void *key);

    // 链表所包含的节点数量
    unsigned long len;

} list;
```

###字典（HashMap）
####源码
```c
/*
 * 哈希表
 *
 * 每个字典都使用两个哈希表，从而实现渐进式 rehash 。
 */
typedef struct dictht {
    
    // 哈希表数组
    dictEntry **table;

    // 哈希表大小
    unsigned long size;
    
    // 哈希表大小掩码，用于计算索引值
    // 总是等于 size - 1
    unsigned long sizemask;

    // 该哈希表已有节点的数量
    unsigned long used;

} dictht;

/*
 * 哈希表节点
 */
typedef struct dictEntry {
    
    // 键
    void *key;

    // 值
    union {
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;

    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;

} dictEntry;

/*
 * 字典
 */
typedef struct dict {

    // 类型特定函数
    dictType *type;

    // 私有数据
    void *privdata;

    // 哈希表 HashTable
    dictht ht[2]; 

    // rehash 索引
    // 当 rehash 不在进行时，值为 -1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */

    // 目前正在运行的安全迭代器的数量
    int iterators; /* number of iterators currently running */

} dict;

/*
 * 字典类型特定函数
 */
typedef struct dictType {

    // 计算哈希值的函数
    unsigned int (*hashFunction)(const void *key);

    // 复制键的函数
    void *(*keyDup)(void *privdata, const void *key);

    // 复制值的函数
    void *(*valDup)(void *privdata, const void *obj);

    // 对比键的函数
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);

    // 销毁键的函数
    void (*keyDestructor)(void *privdata, void *key);
    
    // 销毁值的函数
    void (*valDestructor)(void *privdata, void *obj);

} dictType;

```
####存储原理
- 一般情况下，字典只使用ht[0]，只有再哈希的时候才使用ht[1]。
- 首先对键进行哈希（murmurhash2和DJB HASH）得到哈希值。然后哈希值与哈希表掩码求与得到索引。
- 采用链地址法解决冲突，但最新插入的节点在链表的头部。
####再哈希
Redis 对字典的哈希表执行 rehash 的步骤如下:
1. 为字典的 ht[1] 哈希表分配空间,空间的大小取决于要执行的操作,以及 ht[0]当前包含的键值对数量( used 属性值):

  1. 如果执行的是扩展操作,那么 ht[1] 的大小为第一个大于等于 ht0].used $\times$ 2的 $2^n$.
  2. 如果执行的是收缩操作,那么ht[1]的大小为打一个大于等于 ht[0].used 的$2^n$.

2. 将保存在 ht[0] 中所有键值对 rehash 到 ht[1] 上面: 
  rehash指的是重新计算键的哈希值和索引值,然后键键值对放到 ht[1] 哈希表的指定位置。

3. 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后, 释放 ht[0], 再将 ht[1] 设置为 ht[0],并在 ht[1] 后面创建一个空白的哈希表。

当哈希表的负载因子达到一定条件时，会进行再哈希以收缩或者扩展：
- 负载因子计算公式：load_factor=ht[0].used/ht[0].size

####渐进式 再哈希

**再哈希动作并不是一次性,集中式完成的,而是分多次,渐进式完成的。**

原因：
- 当哈希表里保存的键值对多至百万甚至亿级别时,一次性地全部 rehash 的话,庞大的计算量会对服务器性能造成严重影响.

以下是渐进式 rehash 的步骤:

1. 为 ht[1] 分配空间。
2. 在字典中维持一个索引计数器变量 rehashidx， 将它的值设置为0，表示 rehash 正式开始。
3. 在 rehash 进行期间，每次对字典进行增删改查时，顺带将 ht[0] 在 rehashidx 索引上的所有键值对 rehash 到 ht[1] 中，同时将 rehashidx 加 1。
4. 随着操作不断进行，最终在某个时间点上,，ht[0] 所有的键值对全部 rehash 到 ht[1] 上，这是讲 rehashidx 属性置为 -1，表示 rehash操作完成。
5. 在渐进式 rehash 执行期间,新添加到字典的键值对一律保存到 ht[1] 里，不会对 ht[0] 做添加操作,这一措施保证了 ht[0]只减不增，并随着 rehash 进行， 最终变成空表。

渐进式的 rehash 避免了集中式 rehash 带来的庞大计算量和内存操作。









## 含义##

事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。由于redis 是单线程来处理所有client 的请求的所以做到这点是很容易的。

如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。而一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。

**Redis事务并没有数据库隔离级别的设置和概念，所以当client A开启事务后，另外client B修改了键1，client A GET 1 EXEC后获取的结果是client B修改后的值。防止出现这种情况可以采用开启事务前使用WATCH命令锁定键1，如果client B修改了键1，则client A的事务则整个失败。**

## 错误处理##

- 语法错误。语法错误指命令不存在或者命令参数的个数不对。而只要有一个命令有语法错误，执行EXEC命令后Redis就会直接返回错误。
- 运行错误。运行错误指在命令执行时出现的错误，比如使用散列类型的命令操作集合类型的键，这种错误在实际执行之前Redis是无法发现的，所以在事务里这样的命令是会被Redis接受并执行的。如果事务里的一条命令出现了运行错误，事务里其他的命令依然会继续执行（包括出错命令之后的命令）。

#持久化#

##RDB方式##
RDB方式的持久化是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的所有数据进行快照并存储在硬盘上。进行快照的条件可以由用户在配置文件中自定义，由两个参数构成：时间和改动的键的个数。当在指定的时间内被更改的键的个数大于指定的数值时就会进行快照。RDB是Redis默认采用的持久化方式，在配置文件中已经预置了3个条件：

save 900 1
save 300 10
save 60 10000

save参数指定了快照条件，可以存在多个条件，条件之间是“或”的关系。如上所说，save
900 1的意思是在15分钟（900秒钟）内有至少一个键被更改则进行快照。如果想要禁用自动快
照，只需要将所有的save参数删除即可。

自动save操作是由后台轮询线程记录时间戳和修改次数实现保存。

Redis默认会将快照文件存储在当前目录的dump.rdb文件中，可以通过配置dir和dbfilename两个参数分别指定快照文件的存储路径和文件名。

理清Redis实现快照的过程对我们了解快照文件的特性有很大的帮助。快照的过程如下。
1. Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；
2. 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件；
3. 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此一次快照操作完成。

在执行fork的时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻父子进程共享同一内存数据，当父进程要更改其中某片数据时（如执行一个写命），操作系统会将该片数据复制一份以保证子进程的数据不受影响，所以新的RDB文件存储的是执行fork一刻的内存数据。

通过上述过程可以发现Redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。这使得我们可以通过定时备份RDB文件来

实现Redis数据库备份。RDB文件是经过压缩（可以配置rdbcompression参数以禁用压缩节省CPU占用）的二进制格式，所以占用的空间会小于内存中的数据大小，更加利于传输。
除了自动快照，还可以手动发送**SAVE**或**BGSAVE**命令让Redis执行快照，两个命令的区别在于，前者是由主进程进行快照操作，会阻塞住其他请求，后者会通过fork子进程进行快照操作。

SAVE阻塞当前进程；BGSAVE则fork子进程创建RDB文件，不阻塞当前进程。

Redis启动后会读取RDB快照文件，将数据从硬盘载入到内存。根据数据量大小与结构和服务器性能不同，这个时间也不同。通常将一个记录一千万个字符串类型键、大小为1GB的快照文件载入到内存中需要花费20～30秒钟。

通过RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这就需要开发者根据具体的应用场合，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受的范围。如果数据很重要以至于无法承受任何损失，则可以考虑使用AOF方式进行持久化。

###AOF###

**执行步骤**
命令追加（至aof_buf缓冲区的末尾）—> 

*操作系统 

默认情况下Redis没有开启AOF（append only file）方式的持久化，可以通过appendonly参数开启：
appendonly yes

开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appendonly.aof，可以通过appendfilename参数修改：

appendfilename appendonly.aof

可见AOF文件是纯文本文件，其内容正是Redis客户端向Redis发送的原始通信协议的内容。

随着执行的命令越来越多，AOF文件的大小会越来越大，即使内存中实际的数据可能并没有多少。很自然地，我们希望Redis可以自动优化AOF文件，就上例而言，就是将前两条无用的记录删除，只保留第三条。实际上Redis也正是这样做的，每当达到一定条件时Redis就会自动重写AOF文件，这个条件可以在配置文件中设置：

auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

以上配置的含义是AOF文件的体积大于64MB并且AOF文件的体积比上一次重写之后的体积大了至少100%的时候，Redis将执行REWRITEAOF命令。

auto-aof-rewrite-percentage参数的意义是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时的AOF文件大小为依据。

auto-aof-rewrite-min-size参数限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心。除了让Redis自动执行重写外，我们还可以主动使用**REWRITEAOF**手动执行AOF重写。

在启动时Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相较RDB会慢一些。

*需要注意的是虽然每次执行更改数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒会执行一次同步操作，以便将硬盘缓存中的内容真正地写入硬盘，在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来讲启用AOF持久化的应用都无法容忍这样的损失，这就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在Redis中我们可以通过appendfsync参数设置同步的时机：
appendfsync always
appendfsync everysec（default）
appendfsync no
everysec 规则，即每秒执行一次同步操作。

always表示每次执行写入都会执行同步，这是最安全也是最慢的方式。这种同步策略需要对磁盘进行大量写入，所以Redis处理命令的速度会受到磁盘性能的限制：转盘式硬盘在这种同步频率下每秒只能处理大约200个写命令，而固态硬盘每秒大概也只能处理几万个写命令。

everysec的性能和不使用任何持久化特性时的性能相差无几，而通过每秒同步一次AOF文件，Redis可以保证即使出现系统崩溃，用户也最多只会丢失一秒之内产生的数据。

no表示不主动进行同步操作，而是完全交由操作系统来做（即每30秒一次），这是最快但最不安全的方式。一般情况下使用默认值everysec就足够了，既兼顾了性能又保证了安全。

Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。此时重新启动Redis后Redis会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。

**除了本地持久化以外，建议对RDB文件和AOF文件进行多重异地备份**


#复制#

###含义###

同步后的数据库分为两类，一类是主数据库（master），一类是从数据库（slave）。主数据库可以进行读写操作，当发生写操作时自动将数据同步给从数据库。而从数据库一般是只读的，并接受主数据库同步过来的数据。一个主数据库可以拥有多个从数据库，而一个从数据库只能拥有一个主数据库。

###配置###
- slaveof <masterip> <masterport>
  在从数据库的配置文件中加入slaveof配置即可，主数据库无需进行任何配置。
- masterauth <master-password>
  配置slave复制master使用的权限密码
- requirepass <master-password>

- slave-serve-stale-data yes
  当slave与master断开连接或者同步正在进行时，如果client发生对slave的服务请求：
  设置为yes则slave依然正常提供服务，slave-serve-stale-data设置为no则slave返回client错误："SYNC with master in progress"
- slave-read-only yes
  可以通过设置从数据库的配置文件中的slave-read-only为no以使从数据库可写，但是对从数据库的任何更改都不会同步给任何其他数据库，并且一旦主数据库中更新了对应的数据就会覆盖从数据库中的改动。

###命令###
如果该数据库已经是其他主数据库的从数据库了，SLAVEOF命令会停止和原来数据库的同步转而和新数据库同步。还可以使用SLAVEOF NO ONE来使当前数据库停止接收其他数据库的同步转成主数据库。

###原理###

PSYNC命令具有完整重同步（full resynchronization）和部分重同步（partial resynchronization）两种模式：
- 完整重同步用于处理初次复制情况：完整重同步的执行步骤和SYNC命令的执行步骤基本一样，它们都是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令来进行同步；
- 部分重同步则用于处理断线后重复制情况：当从服务器在断线后重新连接主服务器时，如果条件允许，主服务器可以将主从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接收并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态。

####完整重同步###
从服务器对主服务器的同步操作需要通过向主服务器发送SYNC命令来完成，以下是SYNC命令的执行步骤：
1. 从服务器向主服务器发送SYNC命令；
2. 收到SYNC命令的主服务器执行BGSAVE命令，在后台生成一个RDB文件，并使用一个缓冲区记录从现在开始执行的所有写命令；
3. 当主服务器的BGSAVE命令执行完毕时，主服务器会将BGSAVE命令生成的RDB文件发送给从服务器，从服务器接收并载入这个RDB文件，将自己的数据库状态更新至主服务器执行BGSAVE命令时的数据库状态。
4. 主服务器将记录在缓冲区里面的所有写命令发送给从服务器，从服务器执行这些写命令，将自己的数据库状态更新至主服务器数据库当前所处的状态。

**SYNC命令是一个非常耗费资源的操作**

SYNC命令是非常消耗资源的，因为每次执行SYNC命令，主从服务器需要执行一下操作：
- 主服务器需要执行BGSAVE命令来生成RDB文件，这个生成操作会耗费主服务器大量的CPU、内存和磁盘I/O资源；
- 主服务器需要将自己生成的RDB文件发送给从服务器，这个发送操作会耗费主从服务器大量的网络资源（带宽和流量），并对主服务器响应命令请求的时间产生影响；
- 接收到RDB文件的从服务器需要载入主服务器发来的RDB文件，并且在载入期间，从服务器会因为阻塞而没办法处理命令请求。

###部分重同步###
部分重同步功能由以下三个部分构成：
- 主服务器的复制偏移量（replication offset）和从服务器的复制偏移量；
- 主服务器的复制积压缓冲区（replication backlog）；
- 服务器的运行ID（run ID）。

**复制偏移量**
执行复制的双方——主服务器和从服务器会分别维护一个复制偏移量：
- 主服务器每次向从服务器传播N个字节的数据时，就将自己的复制偏移量的值加上N；
- 从服务器每次收到主服务器传播来的N个字节的数据时，就将自己的复制偏移量的值加上N；

**复制积压缓冲区**
复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为1MB。和普通先进先出队列随着元素的增加和减少而动态调整长度不同，固定长度先进先出队列的长度是固定的，当入队元素的数量大于队列长度时，最先入队的元素会被弹出，而新元素会被放入队列。
当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面。

根据需要调整复制积压缓冲区的大小：

复制积压缓冲区的最小大小可以根据公式second &times; write_size_per_second来估算：
- second为从服务器断线后重新连接上主服务器所需的平均时间（以秒计算）
- write_size_per_second则是主服务器平均每秒产生的写命令数据量（协议格式的写命令的长度总和）
  为了安全起见，可以将复制积压缓冲区的大小设为2 &times; second &times; write_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理。

复制积压缓冲区的大小配置：
repl-backlog-size 1mb

**服务器运行ID**
每个Redis服务器，不论主服务器还是从服务，都会有自己的运行ID：
运行ID在服务器启动时自动生成，由40个随机的十六进制字符组成，例如53b9b28df8042fdc9ab5e3fcbbbabff1d5dce2b3；

当从服务器对主服务器进行初次复制时，主服务器会将自己的运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来。


###命令传播###

在执行完同步操作之后，主从服务器之间数据库状态已经相同了。但这个状态并非一成不变，如果主服务器执行了写操作，那么主服务器的数据库状态就会修改，并导致主从服务器状态不再一致。

所以为了让主从服务器再次回到一致状态，主服务器需要对从服务器执行命令传播操作：主服务器会将自己执行的写命令，也即是造成主从服务器不一致的那条写命令，发送给从服务器执行，当从服务器执行了相同的写命令之后，主从服务器将再次回到一致状态。


###心跳检测###

在命令传播阶段，从服务器默认会以每秒一次的频率，向主服务器发送命令：
REPLCONF ACK <replication_offset>
其中replication_offset是从服务器当前的复制偏移量。
发送REPLCONF ACK命令对于主从服务器有三个作用：
- 检测主从服务器的网络连接状态；
- 辅助实现min-slaves选项；
- 检测命令丢失。

**检测主从服务器的网络连接状态**
如果主服务器超过一秒钟没有收到从服务器发来的REPLCONF ACK命令，那么主服务器就知道主从服务器之间的连接出现问题了。
通过向主服务器发送INFO replication命令，在列出的从服务器列表的lag一栏中，我们可以看到相应从服务器最后一次向主服务器发送REPLCONF ACK命令距离现在过了多少秒，在一般情况下，lag的值应该在0秒或者1秒之间跳动，如果超过1秒的话，那么说明主从服务器之间的连接出现了故障。

**辅助实现min-slaves配置选项**

Redis的min-slaves-to-write和min-slaves-max-lag两个选项可以防止主服务器在不安全的情况下执行写命令。
min-slaves-to-write 3
min-slaves-max-lag 10
那么在从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时，主服务器将拒绝执行写命令，这里的延迟值就是上面提到的INFO replication命令的lag值。

**检测命令丢失**
如果因为网络故障，命令传播在半路丢失，那么当从服务器发送REPLCONF ACK命令时，主服务器发觉复制偏移量不同，就会从复制积压缓冲区找到从服务器丢失的数据，重新发送。



#处理系统故障#

redis-check-aof和redis-check-rdb分别检查AOF和RDB文件的状态，并在有需要的情况下对文件进行修复。但目前RDB文件无法进行修复。







